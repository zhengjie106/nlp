{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. check the grammar: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_check\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def grammar_score(doc):\n",
    "    lc_tool=language_check.LanguageTool('en-US')\n",
    "    \n",
    "    matchs=lc_tool.check(doc)\n",
    "    \n",
    "    mCount=len(matchs)\n",
    "    word_cnt=len(word_tokenize(doc))\n",
    "    \n",
    "    score=0\n",
    "    if mCount >=5: \n",
    "        score=0\n",
    "    else : \n",
    "        score=(word_cnt-mCount)/word_cnt\n",
    "    #print(matchs)\n",
    "    errorlist=[]\n",
    "    error={}\n",
    "    for t in matchs:\n",
    "        errorlist.append(str(t))\n",
    "        #error['offset']=t['offset']\n",
    "        #error['msg']=t['msg']\n",
    "        #errorlist.append(error)\n",
    "        \n",
    "    \n",
    "    msg='This paragraph contains at lest {} program errors: \\n{}'.format(len(matchs), '-'.join(errorlist))\n",
    "    print(msg)\n",
    "    return (score,msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=u'Population is made up of monthly meetings bonus fro DEC to MAY each year, therefore a sample size of two considered adequate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This paragraph contains at lest 2 program errors: \n",
      "Line 1, column 34, Rule ID: POSSESSIVE_APOSTROPHE[1]\n",
      "Message: Possible typo: apostrophe is missing. Did you mean 'meetings'' or 'meeting's'?\n",
      "Suggestion: meetings'; meeting's\n",
      "Population is made up of monthly meetings bonus fro DEC to MAY each year, therefo...\n",
      "                                 ^^^^^^^^-Line 1, column 49, Rule ID: FOR_FRO[1]\n",
      "Message: Did you mean 'for' or 'from'?\n",
      "Suggestion: for; from\n",
      "...on is made up of monthly meetings bonus fro DEC to MAY each year, therefore a sampl...\n",
      "                                           ^^^\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9130434782608695,\n",
       " \"This paragraph contains at lest 2 program errors: \\nLine 1, column 34, Rule ID: POSSESSIVE_APOSTROPHE[1]\\nMessage: Possible typo: apostrophe is missing. Did you mean 'meetings'' or 'meeting's'?\\nSuggestion: meetings'; meeting's\\nPopulation is made up of monthly meetings bonus fro DEC to MAY each year, therefo...\\n                                 ^^^^^^^^-Line 1, column 49, Rule ID: FOR_FRO[1]\\nMessage: Did you mean 'for' or 'from'?\\nSuggestion: for; from\\n...on is made up of monthly meetings bonus fro DEC to MAY each year, therefore a sampl...\\n                                           ^^^\")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_score(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Similarity check: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_check(doc):\n",
    "    text=doc.lower()\n",
    "    word_cnt=len(word_tokenize(text))\n",
    "    with open('population1.json') as f:\n",
    "        data=json.load(f)\n",
    "    match_cnt=0\n",
    "    keywords={}\n",
    "    for example in data['rasa_nlu_data']['common_examples']:\n",
    "        ents={}\n",
    "        entlist=[]\n",
    "        for entitem in example['entities']: \n",
    "            t=entitem['value']\n",
    "            key=entitem['entity']\n",
    "            if text.find(t.lower())>=0:\n",
    "                #match\n",
    "                match_cnt=match_cnt+1\n",
    "                if key in keywords : \n",
    "                    valuelist=keywords.get(key)\n",
    "                    valuelist.append(t)\n",
    "                else: \n",
    "                    valuelist=[]\n",
    "                    valuelist.append(t)\n",
    "                    keywords[key]=valuelist\n",
    "    for k in keywords.keys(): \n",
    "        s=set(keywords[k])\n",
    "        keywords[k]=s\n",
    "        \n",
    "    y=0\n",
    "    if 'source_data' in keywords: \n",
    "        if 'frequency' in keywords or 'control_verb' in keywords: \n",
    "            y=1\n",
    "        else: \n",
    "            y=0.5\n",
    "    else: \n",
    "        y=0    \n",
    "\n",
    "    return (y,str(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " \"{'frequency': {'monthly', ' monthly'}, 'source_data': {'tracker and action logs'}}\")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_check('The monthly tracker and action logs for the previous 12 months.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "import spacy\n",
    "nlp=spacy.load('en')\n",
    "from rasa_nlu.model import Metadata, Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_check(doc): \n",
    "    interpreter=Interpreter.load('/Users/liver/jupyter/audit_pop1/default/model_20180918-232732/')\n",
    "    result=interpreter.parse(doc)\n",
    "    return('The paragraph is classified as {} in the confidence level of {}'.format(result['intent']['name'],result['intent']['confidence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The paragraph is classified as good1 in the confidence level of 0.8629302579651378'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='Population is the 10 FCC staff in HMLG. Job descriptions for FCC staff are reviewed annually and it was proposed to test whether job descriptions include adequate reference to control of financial crime risk.'\n",
    "classification_check(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " \"entitiys are found in 2 type(s):{'frequency': ['monthly'], 'source_data': ['tracker and action logs']}\")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "def ner_extraction(doc): \n",
    "    output_dir='/Users/liver/jupyter/audit-pop1-ner-train'\n",
    "    nlp2=spacy.load(output_dir)\n",
    "    doc=nlp2(doc)\n",
    "    #ents=[(ent.text, ent.label_) for ent in doc.ents]\n",
    "    entlist={}\n",
    "    \n",
    "    for ent in doc.ents: \n",
    "        txt=ent.text\n",
    "        lab=ent.label_\n",
    "        if lab in entlist : \n",
    "            valuelist=entlist.get(lab)\n",
    "            valuelist.append(txt)\n",
    "        else: \n",
    "            valuelist=[]\n",
    "            valuelist.append(txt)\n",
    "            entlist[lab]=valuelist\n",
    "    #generate score\n",
    "    iScore=0\n",
    "    y=0\n",
    "    if 'source_data' in entlist: \n",
    "        if 'frequency' in entlist or 'control_verb' in entlist: \n",
    "            y=1\n",
    "        else: \n",
    "            y=0.5\n",
    "    else: \n",
    "        y=0\n",
    "    \n",
    "    return(y,\"entitiys are found in {} type(s):{}\".format(len(entlist), str(entlist)))\n",
    "    \n",
    "\n",
    "\n",
    "#pupulation 1 \n",
    "text='The monthly tracker and action logs for the previous 12 months.'\n",
    "ner_extraction(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t1': [], 't2': []}\n"
     ]
    }
   ],
   "source": [
    "t={'t1':'v1','t2':'v2', 't2':'v3'}\n",
    "entlist={}\n",
    "\n",
    "for ti in t.keys():\n",
    "    valuelist=[]\n",
    "    entlist[ti]=valuelist\n",
    "for ti in t: \n",
    "    \n",
    "    \n",
    "print(str(entlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
